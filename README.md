# â˜ï¸ Local Serverless Data Pipeline (Colab Edition)

![Pipeline Demo](https://media.tenor.com/LCJMufd4bDkAAAAi/satu-data-animation.gif)

A fully working **serverless-style data pipeline** built entirely with **Python**, designed to run right inside **Google Colab** â€” no AWS account, no setup, and no edits required.


It behaves like an **AWS S3 â†’ Lambda â†’ DynamoDB â†’ S3 (processed)** workflow but runs locally using folders and JSON files to emulate the cloud.

---

## ğŸš€ Overview

Whenever you drop a file (like `data.txt`) into the **`inbox/`** folder:
1. A â€œLambda ingestionâ€ function is triggered automatically ğŸ§©  
2. Metadata about the file (like name, timestamp, and status) is stored in **`data/metadata.jsonl`** ğŸ—‚ï¸  
3. A â€œLambda transformâ€ function reads that file, converts its text to uppercase, and saves it in **`processed/`** ğŸ’¾  

All this happens in real time inside Colab â€” no dependencies, no cloud costs, no setup hassles.

---

## ğŸ§± Architecture

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ inbox/ â”‚ â† "S3 Bucket" for uploads
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
â”‚
(event detected)
â”‚
â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ingestion_handler â”‚ â†’ writes metadata
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ data/metadata.jsonlâ”‚ â† "DynamoDB Table"
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ transform_handler â”‚ â†’ uppercases content
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ processed/ â”‚ â† "Processed output bucket"
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

yaml
Copy code

---

## ğŸ§° Tech Stack

| Component | Technology Used |
|------------|-----------------|
| Language | Python 3 (no dependencies) |
| Cloud Concept | AWS Lambda, S3, DynamoDB |
| Runtime | Google Colab or local Python |
| Data Storage | Local JSON Lines file |
| Triggering | Polling-based event detection |

---

## ğŸ“ Folder Structure

ğŸ“¦ project-root
â”£ ğŸ“‚ inbox/ # Incoming "uploads"
â”£ ğŸ“‚ processed/ # Output folder
â”£ ğŸ“‚ data/ # Stores metadata file
â”£ ğŸ“œ main.py # Main watcher script
â”— ğŸ“œ README.md

markdown
Copy code

---

## ğŸ§ª Quickstart (Colab-Friendly)

### 1ï¸âƒ£ Open Google Colab
- Create a new notebook.
- Copy and paste the full Python code from the main script into a cell.
- Run the cell â€” it starts the watcher automatically.

### 2ï¸âƒ£ Upload a File
In Colabâ€™s **left sidebar â†’ Files tab**:
- Find or create the folder `inbox/`
- Upload any `.txt` file (for example `test.txt`)

The pipeline detects the upload instantly and:
- Creates `processed/test.txt` with uppercased content
- Logs metadata to `data/metadata.jsonl`

Youâ€™ll see output like:

âœ… Processed 'test.txt' at 14:32:19

yaml
Copy code

---

## ğŸ§¾ Example Metadata (data/metadata.jsonl)

Each line is a JSON record:
```json
{"fileKey": "test.txt", "bucket": "inbox", "status": "RECEIVED", "ingestedAt": "2025-10-16T14:32:19.123Z"}
This acts like a DynamoDB table â€” one record per processed file.

âš™ï¸ Configuration (Environment Variables)
Variable	Default	Description
INBOX_DIR	inbox	Folder for incoming files
PROCESSED_DIR	processed	Folder for transformed output
DATA_DIR	data	Folder where metadata lives
METADATA_FILE	data/metadata.jsonl	Metadata log file
POLL_INTERVAL	1.5	Seconds between folder checks

You donâ€™t need to set any of these in Colab â€” defaults are perfect for testing.

ğŸ§­ How to Stop the Pipeline
In Colab, just click Stop (â– ) in the toolbar â€” it halts the watch loop safely.

ğŸ§¹ Cleanup
When youâ€™re done, remove generated folders:

bash
Copy code
!rm -rf inbox processed data
ğŸ’¡ Extend This Project
Here are some cool ways to make it more realistic or advanced:

ğŸª£ Replace the folder-based system with real S3 uploads using boto3

 Add a data validation step before writing metadata

ğŸ“ˆ Stream metrics to CloudWatch or Grafana

ğŸ”„ Convert the watcher into a Flask API or FastAPI endpoint

â˜ï¸ Deploy the same logic to AWS Lambda and test with actual S3 triggers

ğŸ¥ Demo GIF (Placeholder)
Replace this with your own demo GIF when you record the pipeline running:


ğŸªª License
MIT License Â© 2025 â€” free to use, modify, and share.

â¤ï¸ Author Notes
This Colab edition is made to teach cloud concepts without AWS setup.
Itâ€™s a great base to practice serverless thinking, event-driven design, and data engineering logic â€” all inside your browser.

yaml
Copy code
