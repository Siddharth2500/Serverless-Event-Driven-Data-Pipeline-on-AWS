{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yE-lwLn06lK",
        "outputId": "c0e684da-6d4a-4833-f9f7-64dda79bf805"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Starting local serverless-like data pipeline demo in Colab...\n",
            "\n",
            "üìù Created: inbox/example.txt\n",
            "üì¶ Watching folder: inbox\n",
            "üìë Metadata file: data/metadata.jsonl\n",
            "‚öôÔ∏è  Drop any .txt file into the 'inbox' folder to trigger processing.\n",
            "üîÅ Press Stop (‚ñ†) in Colab toolbar to end.\n",
            "\n",
            "‚úÖ Processed 'example.txt' at 08:53:19\n",
            "üõë Pipeline stopped by user.\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# CLOUD PIPELINE EMULATOR (RUNS DIRECTLY IN GOOGLE COLAB)\n",
        "# ============================================================\n",
        "\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "from datetime import datetime, timezone\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "INBOX = \"inbox\"\n",
        "PROCESSED = \"processed\"\n",
        "DATA_DIR = \"data\"\n",
        "METADATA_FILE = os.path.join(DATA_DIR, \"metadata.jsonl\")\n",
        "POLL_INTERVAL = 1.5  # seconds\n",
        "\n",
        "os.makedirs(INBOX, exist_ok=True)\n",
        "os.makedirs(PROCESSED, exist_ok=True)\n",
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# HANDLER: INGESTION (like AWS Lambda for S3 -> DynamoDB)\n",
        "# ============================================================\n",
        "def ingestion_handler(event):\n",
        "    try:\n",
        "        records = event.get(\"Records\", [])\n",
        "        for record in records:\n",
        "            s3 = record.get(\"s3\", {})\n",
        "            bucket = s3.get(\"bucket\", {}).get(\"name\")\n",
        "            key = s3.get(\"object\", {}).get(\"key\")\n",
        "\n",
        "            # append metadata line\n",
        "            metadata = {\n",
        "                \"fileKey\": key,\n",
        "                \"bucket\": bucket,\n",
        "                \"status\": \"RECEIVED\",\n",
        "                \"ingestedAt\": datetime.now(timezone.utc).isoformat(),\n",
        "            }\n",
        "            with open(METADATA_FILE, \"a\", encoding=\"utf-8\") as f:\n",
        "                f.write(json.dumps(metadata) + \"\\n\")\n",
        "\n",
        "        return {\"statusCode\": 200, \"body\": json.dumps({\"message\": \"Metadata stored\"})}\n",
        "\n",
        "    except Exception as e:\n",
        "        return {\"statusCode\": 500, \"body\": json.dumps({\"error\": str(e)})}\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# HANDLER: TRANSFORM (like ETL Lambda)\n",
        "# ============================================================\n",
        "def transform_handler(event):\n",
        "    try:\n",
        "        for record in event.get(\"Records\", []):\n",
        "            s3 = record.get(\"s3\", {})\n",
        "            bucket = s3.get(\"bucket\", {}).get(\"name\")\n",
        "            key = s3.get(\"object\", {}).get(\"key\")\n",
        "\n",
        "            src_path = os.path.join(bucket, key)\n",
        "            dst_path = os.path.join(PROCESSED, key)\n",
        "            os.makedirs(os.path.dirname(dst_path), exist_ok=True)\n",
        "\n",
        "            # read and transform (uppercase)\n",
        "            with open(src_path, \"r\", encoding=\"utf-8\") as f:\n",
        "                content = f.read()\n",
        "            transformed = content.upper()\n",
        "\n",
        "            # write processed version\n",
        "            with open(dst_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                f.write(transformed)\n",
        "\n",
        "        return {\"statusCode\": 200, \"body\": json.dumps(\"Transformation complete\")}\n",
        "\n",
        "    except Exception as e:\n",
        "        return {\"statusCode\": 500, \"body\": json.dumps({\"error\": str(e)})}\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# FUNCTION: TRIGGER EVENT (simulate S3 event)\n",
        "# ============================================================\n",
        "def make_s3_event(file_path):\n",
        "    return {\n",
        "        \"Records\": [\n",
        "            {\n",
        "                \"s3\": {\n",
        "                    \"bucket\": {\"name\": INBOX},\n",
        "                    \"object\": {\"key\": os.path.basename(file_path)},\n",
        "                }\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# MAIN PIPELINE RUNNER\n",
        "# ============================================================\n",
        "def run_pipeline():\n",
        "    print(\"üì¶ Watching folder:\", INBOX)\n",
        "    print(\"üìë Metadata file:\", METADATA_FILE)\n",
        "    print(\"‚öôÔ∏è  Drop any .txt file into the 'inbox' folder to trigger processing.\")\n",
        "    print(\"üîÅ Press Stop (‚ñ†) in Colab toolbar to end.\\n\")\n",
        "\n",
        "    seen = set()\n",
        "    os.makedirs(INBOX, exist_ok=True)\n",
        "\n",
        "    while True:\n",
        "        files = [f for f in os.listdir(INBOX) if os.path.isfile(os.path.join(INBOX, f))]\n",
        "        for file in files:\n",
        "            if file in seen:\n",
        "                continue\n",
        "            path = os.path.join(INBOX, file)\n",
        "            event = make_s3_event(path)\n",
        "            ingestion_handler(event)\n",
        "            transform_handler(event)\n",
        "            seen.add(file)\n",
        "            print(f\"‚úÖ Processed '{file}' at {datetime.now().strftime('%H:%M:%S')}\")\n",
        "\n",
        "        time.sleep(POLL_INTERVAL)\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# EXAMPLE: CREATE A SAMPLE FILE\n",
        "# ============================================================\n",
        "def create_sample_file():\n",
        "    os.makedirs(INBOX, exist_ok=True)\n",
        "    file_path = os.path.join(INBOX, \"example.txt\")\n",
        "    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(\"hello from colab\")\n",
        "    print(\"üìù Created:\", file_path)\n",
        "    return file_path\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# QUICK DEMO\n",
        "# ============================================================\n",
        "print(\"üöÄ Starting local serverless-like data pipeline demo in Colab...\\n\")\n",
        "\n",
        "# create a sample file for demo\n",
        "create_sample_file()\n",
        "\n",
        "# run the watcher loop for a short demo\n",
        "# (You can stop it manually in Colab with the stop button.)\n",
        "try:\n",
        "    run_pipeline()\n",
        "except KeyboardInterrupt:\n",
        "    print(\"üõë Pipeline stopped by user.\")\n"
      ]
    }
  ]
}